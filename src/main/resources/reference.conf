cassandra-journal {

  # FQCN of the cassandra journal plugin
  class = "akka.persistence.cassandra.journal.CassandraJournal"

  # Comma-separated list of contact points in the cluster
  contact-points = ["127.0.0.1"]

  # Port of contact points in the cluster
  port = 9042

  # Name of the keyspace to be created/used by the journal
  keyspace = "akka"

  # Parameter indicating whether the journal keyspace should be auto created
  keyspace-autocreate = true

  # In case that schema creation failed you can define a number of retries before giving up.
  keyspace-autocreate-retries = 1

  # Deletes are achieved using a metadata entry and then the actual messages are deleted asynchronously
  # Number of retries before giving up
  delete-retries = 3
  
  # Number of retries before giving up connecting to the cluster
  connect-retries = 3
  
  # Delay between connection retries
  connect-retry-delay = 5s

  # Name of the table to be created/used by the journal
  table = "messages"

  # Compaction strategy for the journal table
  table-compaction-strategy {
    class = "SizeTieredCompactionStrategy"
  }

  # Name of the table to be created/used for storing metadata
  metadata-table = "metadata"

  # Name of the table to be created/used for journal config
  config-table = "config"
  
  # Name of the materialized view for eventsByTag query
  events-by-tag-view = "eventsbytag"

  # replication strategy to use. SimpleStrategy or NetworkTopologyStrategy
  replication-strategy = "SimpleStrategy"

  # Replication factor to use when creating a keyspace. Is only used when replication-strategy is SimpleStrategy.
  replication-factor = 1

  # Replication factor list for data centers, e.g. ["dc1:3", "dc2:2"]. Is only used when replication-strategy is NetworkTopologyStrategy.
  data-center-replication-factors = []

  # Write consistency level
  write-consistency = "QUORUM"

  # Read consistency level
  read-consistency = "QUORUM"

  max-message-batch-size = 200

  # Target number of entries per partition (= columns per row).
  # Must not be changed after table creation (currently not checked).
  # This is "target" as AtomicWrites that span parition boundaries will result in bigger partitions to ensure atomicity.
  target-partition-size = 500000

  # Maximum size of result set
  max-result-size = 50001

  # Dispatcher for the plugin actor.
  plugin-dispatcher = "akka.actor.default-dispatcher"

  # Dispatcher for fetching and replaying messages
  replay-dispatcher = "akka.persistence.dispatchers.default-replay-dispatcher"

  # The time to wait before cassandra will remove the thombstones created for deleted entries.
  # cfr. gc_grace_seconds table property documentation on http://www.datastax.com/documentation/cql/3.1/cql/cql_reference/tabProp.html
  gc-grace-seconds = 864000
  
  # Configure know tags in this section
  # tagname = tagid
  # where tagid must be 1, 2, or 3. Max 3 tags per event is supported.
  # For example:
  #   BlogPosts = 1
  #   Announcement = 2
  #   Authors = 1
  # With those tag identifiers you can use BlogPosts and Announcement for a single event,
  # but you cannot combine BlogPosts and Authors, since they have the same tag identifier.  
  tags {
  }
}

cassandra-snapshot-store {

  # FQCN of the cassandra snapshot store plugin
  class = "akka.persistence.cassandra.snapshot.CassandraSnapshotStore"

  # Comma-separated list of contact points in the cluster
  contact-points = ["127.0.0.1"]

  # Port of contact points in the cluster
  port = 9042

  # Name of the keyspace to be created/used by the snapshot store
  keyspace = "akka_snapshot"

  # Parameter indicating whether the snapshot keyspace should be auto created
  keyspace-autocreate = true

  # In case that schema creation failed you can define a number of retries before giving up.
  keyspace-autocreate-retries = 1
  
  # Number of retries before giving up connecting to the cluster
  connect-retries = 3
  
  # Delay between connection retries
  connect-retry-delay = 5s

  # Name of the table to be created/used by the snapshot store
  table = "snapshots"

  # Compaction strategy for the snapshot table
  table-compaction-strategy {
    class = "SizeTieredCompactionStrategy"
  }

  # Name of the table to be created/used for journal config
  config-table = "config"

  # Name of the table to be created/used for storing metadata
  metadata-table = "metadata"

  # replication strategy to use. SimpleStrategy or NetworkTopologyStrategy
  replication-strategy = "SimpleStrategy"

  # Replication factor to use when creating a keyspace. Is only used when replication-strategy is SimpleStrategy.
  replication-factor = 1

  # Replication factor list for data centers, e.g. ["dc1:3", "dc2:2"]. Is only used when replication-strategy is NetworkTopologyStrategy.
  data-center-replication-factors = []

  # Write consistency level
  write-consistency = "ONE"

  # Read consistency level
  read-consistency = "ONE"

  # Maximum number of snapshot metadata to load per recursion (when trying to
  # find a snapshot that matches specified selection criteria). Only increase
  # this value when selection criteria frequently select snapshots that are
  # much older than the most recent snapshot i.e. if there are much more than
  # 10 snapshots between the most recent one and selected one. This setting is
  # only for increasing load efficiency of snapshots.
  max-metadata-result-size = 10

  # Maximum size of result set
  max-result-size = 50001

  # Dispatcher for the plugin actor.
  plugin-dispatcher = "cassandra-snapshot-store.default-dispatcher"

  # Default dispatcher for plugin actor.
  default-dispatcher {
    type = Dispatcher
    executor = "fork-join-executor"
    fork-join-executor {
      parallelism-min = 2
      parallelism-max = 8
    }
  }
}

# Configuration for the CassandraReadJournal
cassandra-query-journal {
  # Implementation class of the Cassandra ReadJournalProvider
  class = "akka.persistence.cassandra.query.CassandraReadJournalProvider"
  
  # Absolute path to the write journal plugin configuration section
  write-plugin = "cassandra-journal"
  
  # New events are retrieved (polled) with this interval.
  refresh-interval = 3s
  
  # How many events to fetch in one query (replay) and keep buffered until they
  # are delivered downstreams.
  max-buffer-size = 100
  
  # The fetch size of the Cassandra select statement
  fetch-size = 50
  
  # Read consistency level
  read-consistency = "QUORUM"
  
  # Configure this to the day (yyyyMMdd) when the system was first started.
  # When offset 0L is used it will look for events from this day and forward.
  first-time-bucket = "20151120"

  # The returned event stream is ordered by the offset (timestamp), which corresponds
  # to the same order as the write journal stored the events, with inaccuracy due to clock skew
  # between different nodes. The same stream elements (in same order) are returned for multiple
  # executions of the query on a best effort basis. The query is using a Cassandra Materialized
  # View for the query and that is eventually consistent, so different queries may see different
  # events for the latest events, but eventually the result will be ordered by timestamp
  # (Cassandra timeuuid column). To compensate for the the eventual consistency the query is
  # delayed to not read the latest events, the duration of this delay is defined by this 
  # configuration property.
  # However, this is only best effort and in case of network partitions
  # or other things that may delay the updates of the Materialized View the events may be
  # delivered in different order (not strictly by their timestamp).  
  eventual-consistency-delay = 10s
  
  # For each `persistenceId` the events are delivered strictly by sequence number. If
  # a sequence number is missing the query is delayed up to the configured
  # `wrong-sequence-number-order-timeout` and if the expected event is still not found
  # the stream is completed with failure.
  wrong-sequence-number-order-timeout = 30s
  
  # Dispatcher for the plugin actors.
  plugin-dispatcher = "akka.actor.default-dispatcher"
}